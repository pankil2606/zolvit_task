{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVR3akARsqKH",
        "outputId": "edcc2b39-79ea-4748-dc59-8055085048c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (10.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the ZIP file in Colab (for example, from your Google Drive)\n",
        "zip_file_path = '/content/sample_data/zolvit.zip'  # Replace with your actual ZIP file path\n",
        "\n",
        "# Directory where you want to extract the contents\n",
        "extract_to_dir = '/content/extracted_folder/'  # Replace with your desired extraction path\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(extract_to_dir, exist_ok=True)\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_dir)\n",
        "\n",
        "print(f\"Files extracted to: {extract_to_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtENYOVQtEpG",
        "outputId": "50331ba8-2ecc-4ae7-d5ac-f6a5482efd49"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to: /content/extracted_folder/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import re\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "# Directory containing your PDFs\n",
        "pdf_directory = '/content/extracted_folder'\n",
        "output_csv = 'invoice_data_2.csv'\n",
        "\n",
        "def extract_table_from_pdf(pdf_path, page_num=0):\n",
        "    # Define bounding boxes for each column based on x-coordinates\n",
        "    columns = {\n",
        "        \"Item\": (50, 250),           # Item description column\n",
        "    }\n",
        "\n",
        "    # Open the PDF and access the specified page\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        page = pdf.pages[page_num]\n",
        "\n",
        "        # Create empty lists to hold column data\n",
        "        data = {col: [] for col in columns}\n",
        "        start_extracting = False  # Flag to start extracting data after \"Item\" header\n",
        "\n",
        "        # Find the position of \"Taxable Amount\" to determine y_end\n",
        "        y_start = 0\n",
        "        y_end = None  # Initialize y_end as None\n",
        "\n",
        "        # Read all lines to find \"Taxable Amount\" position\n",
        "        lines = page.extract_text().splitlines()\n",
        "        for line in lines:\n",
        "            if \"Taxable Amount\" in line:\n",
        "                # Get the y-coordinate of the line\n",
        "                # Using the line number as a rough estimate for y-coordinate\n",
        "\n",
        "                y_end = lines.index(line) * 20   # Assuming approx. 15 pixels per line, adjust as necessary\n",
        "                break  # Stop searching after finding \"Taxable Amount\"\n",
        "\n",
        "        if y_end is None:\n",
        "            y_end = 600  # Fallback if \"Taxable Amount\" is not found\n",
        "\n",
        "        for col_name, (x_start, x_end_col) in columns.items():\n",
        "            # Crop each column area from the page within the specified bounding box\n",
        "            cropped = page.within_bbox((x_start, y_start, x_end_col, y_end))\n",
        "            text = cropped.extract_text()\n",
        "\n",
        "            # Process text if available\n",
        "            if text:\n",
        "                processed_text = []\n",
        "                for line in text.splitlines():\n",
        "                    # Check if we should start extracting data\n",
        "                    if \"Item\" in line:\n",
        "                        start_extracting = True  # Set flag to true when we detect \"Item\" header\n",
        "                        continue  # Skip the header line\n",
        "\n",
        "                    if start_extracting:\n",
        "                        line = line.strip()\n",
        "                                          # Check for \"ems\" or \"Qty\" to stop extracting further text\n",
        "                        if 'ems' in line.lower() or 'qty' in line.lower():\n",
        "                            stop_extracting = True  # Set the flag to stop extracting\n",
        "                            break  # Exit the loop if we find \"ems\" or \"Qty\"\n",
        "                        # Handle hyphenated lines by checking if the current line ends with a hyphen\n",
        "                        # print(processed_text)\n",
        "                        if(line.startswith('&')):\n",
        "\n",
        "\n",
        "                            line = re.sub(r'\\b(?<!\\d)(\\d+)(?!([a-zA-Z]|\\'\\w*))\\b', '', line)\n",
        "                            processed_text[-1]  += (' '+line)\n",
        "\n",
        "                        elif(\"Face Wash Gel\" in line):\n",
        "\n",
        "                            line = re.sub(r'\\b(?<!\\d)(\\d+)(?!([a-zA-Z]|\\'\\w*))\\b', '', line)\n",
        "                            processed_text[-1]  += (' '+line)\n",
        "\n",
        "\n",
        "                        # elif (processed_text and processed_text[-1].endswith(' - |- |-| \\d+|&|& ')):\n",
        "                        elif (processed_text and (processed_text[-1].endswith(' - ') or processed_text[-1].endswith('- ') or processed_text[-1].endswith('-') or processed_text[-1].endswith(' \\d+') or processed_text[-1].endswith('& ') or processed_text[-1].endswith('& '))):\n",
        "                          # Remove standalone integers not followed by letters (but keep decimals)\n",
        "                            # line = re.sub(r'\\b(?<!\\d)\\d+\\b(?!\\s*[a-zA-Z])', '', line)\n",
        "\n",
        "                            line = re.sub(r'\\b(?<!\\d)(\\d+)(?!([a-zA-Z]|\\'\\w*))\\b', '', line)\n",
        "\n",
        "                            processed_text[-1] += (' '+line)   # Remove hyphen and join with previous line\n",
        "\n",
        "                        else:\n",
        "\n",
        "                            line = line.replace(';', '\\n')\n",
        "\n",
        "                            # Keep valid decimal numbers with units intact\n",
        "                            # line = re.sub(r'(?<!\\d)(\\d+(\\.\\d+)?)\\s*(mg|ml|ML|MG)\\b', r'\\1 \\3', line)  # Correctly match numbers with units\n",
        "                            # line = re.sub(r'(?<!\\d)(\\d+(\\.\\d+)?|\\d+)\\s*(mg|ml|ML|MG)\\b', r'\\1 \\3', line)  # Match both integers and decimals with units\n",
        "                            line = re.sub(r'(\\d+(\\.\\d+)?|\\d+)\\s*(mg|ml|ML|MG)', r'\\1 \\3', line)\n",
        "\n",
        "                            line = re.sub(r'(?<!\\d)(-\\d+(\\.\\d+)?)\\s*\\b', '', line)  # Remove negative numbers\n",
        "                            line = re.sub(r'\\b\\d+\\.\\d{2}\\b', '', line)  # Remove numbers with exactly two decimal places\n",
        "\n",
        "                            # Remove standalone integers not followed by letters (but keep decimals)\n",
        "                            # line = re.sub(r'\\b(?<!\\d)\\d+\\b(?!\\s*[a-zA-Z])', '', line)\n",
        "                            line = re.sub(r'\\b(?<!\\d)(\\d+)(?!(\\s*[a-zA-Z]|\\'\\w*))\\b', '', line)\n",
        "\n",
        "\n",
        "                            line = re.sub(r'(?<!\\d)\\.(?!\\d)', '', line)  # Remove standalone periods while preserving decimals within text\n",
        "\n",
        "                            # Merge lines ending with a comma with the previous line\n",
        "                            if processed_text and line.endswith(','):\n",
        "                                processed_text[-1] += ' ' + line[:-1]  # Remove comma and merge\n",
        "                            elif line.strip():  # Only append non-empty lines\n",
        "                                processed_text.append(line)\n",
        "\n",
        "                data[col_name] = processed_text\n",
        "\n",
        "        # Adjust length of each column list to match the longest column\n",
        "        max_len = max(len(values) for values in data.values())\n",
        "        for key in data:\n",
        "            data[key] += [''] * (max_len - len(data[key]))\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "def extract_invoice_data(pdf_path):\n",
        "    extracted_data = \"\"\n",
        "\n",
        "    # Use pdfplumber to read PDF\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            extracted_data += page.extract_text() + \"\\n\"  # Extract text from each page\n",
        "\n",
        "    # Patterns for extracting invoice details\n",
        "    patterns = {\n",
        "        \"invoice_number\": r\"Invoice #:\\s*(INV-\\d+)\",  # Invoice number\n",
        "        \"invoice_date\": r\"Invoice Date:\\s*(\\d{2}\\s[A-Za-z]{3}\\s\\d{4})\",  # Invoice date\n",
        "        \"due_date\": r\"Due Date:\\s*(\\d{2}\\s[A-Za-z]{3}\\s\\d{4})\",  # Due date\n",
        "        \"taxable_amount\": r\"Taxable Amount ₹([\\d,.]+)\",  # Taxable amount\n",
        "        \"cgst\": r\"CGST\\s+\\d+\\.\\d+\\%\\s+₹([\\d,.]+)\",  # CGST amount\n",
        "        \"sgst\": r\"SGST\\s+\\d+\\.\\d+\\%\\s+₹([\\d,.]+)\",  # SGST amount\n",
        "        \"total_amount\": r\"Total ₹([\\d,.]+)\",  # Total amount\n",
        "        \"total_discount\": r\"Total Discount ₹([\\d,.]+)\",  # Total discount\n",
        "        \"total_items_qty\": r\"Total Items / Qty\\s*:\\s*(\\d+)\\s*/\\s*(\\d+)\",  # Total items / qty\n",
        "        \"amount_in_words\": r\"Total amount \\(in words\\):\\s*(.*)\",  # Amount in words\n",
        "\n",
        "    }\n",
        "\n",
        "    invoice_data = {}\n",
        "\n",
        "    # Extract key fields using the defined patterns\n",
        "    for key, pattern in patterns.items():\n",
        "        match = re.search(pattern, extracted_data, re.MULTILINE)\n",
        "        if match:\n",
        "            invoice_data[key] = match.group(1).strip()\n",
        "        else:\n",
        "            # Set default values for CGST and SGST to 0 if not found\n",
        "            if key in [\"cgst\", \"sgst\"]:\n",
        "                invoice_data[key] = 0\n",
        "            else:\n",
        "                invoice_data[key] = None\n",
        "\n",
        "\n",
        "    # Regex pattern for customer details\n",
        "    customer_details_pattern = r\"Customer Details:\\s*(.*?)\\n\"\n",
        "\n",
        "    # Apply the pattern to the text\n",
        "    match = re.search(customer_details_pattern, extracted_data, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        customer_details_line = match.group(1).strip()  # Capture the customer details line\n",
        "\n",
        "        # Check if the captured customer name is \"Shipping Address:\"\n",
        "               # Check if the captured customer details are \"Shipping Address:\" or \"Billing Address:\"\n",
        "        if customer_details_line == \"Shipping Address:\" or customer_details_line == \"Billing Address:\":\n",
        "            # Create a regex pattern to match either \"Shipping Address:\" or \"Billing Address:\"\n",
        "            address_pattern = r\"(Shipping Address:|Billing Address:)\\s*(\\S+\\s+\\S+)\"\n",
        "            address_match = re.search(address_pattern, extracted_data)\n",
        "            if address_match:\n",
        "                customer_name = address_match.group(2)  # Get the next two words after either address\n",
        "            else:\n",
        "                customer_name = \"\"  # Default to empty if not found\n",
        "        else:\n",
        "            customer_name = customer_details_line  # Otherwise, use the captured name\n",
        "\n",
        "        invoice_data[\"customer_name\"] = customer_name\n",
        "        invoice_data[\"shipping_address\"] = \"\"  # Assuming you don't need to extract shipping address\n",
        "\n",
        "\n",
        "    # Extract the item column from the PDF\n",
        "    item_df = extract_table_from_pdf(pdf_path)\n",
        "    invoice_data[\"items\"] = item_df[\"Item\"].tolist() if not item_df.empty else []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return invoice_data\n",
        "\n",
        "# Function to process all PDF files in the directory\n",
        "def process_all_pdfs(pdf_directory):\n",
        "    extracted_data_list = []\n",
        "\n",
        "    for filename in os.listdir(pdf_directory):\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(pdf_directory, filename)\n",
        "            print(f\"Processing {filename}...\")\n",
        "\n",
        "            # Extract invoice data from the PDF\n",
        "            invoice_data = extract_invoice_data(pdf_path)\n",
        "\n",
        "            # Extract invoice number from the filename (if not found in text)\n",
        "            if not invoice_data.get(\"invoice_number\"):\n",
        "                invoice_data[\"invoice_number\"] = extract_invoice_number_from_filename(filename)\n",
        "\n",
        "            extracted_data_list.append(invoice_data)\n",
        "\n",
        "    return extracted_data_list\n",
        "\n",
        "# Function to save extracted data to a CSV file\n",
        "def save_data_to_csv(extracted_data_list, output_csv):\n",
        "    with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([  # CSV header\n",
        "            \"Invoice Number\", \"Invoice Date\", \"Due Date\", \"Customer Name\",\"Items\",\n",
        "             \"Taxable Amount\", \"CGST\", \"SGST\", \"Total Amount\",\n",
        "            \"Total Discount\", \"Total Items / Qty\", \"Amount in Words\"\n",
        "        ])\n",
        "\n",
        "        for data in extracted_data_list:\n",
        "            writer.writerow([\n",
        "                data[\"invoice_number\"],\n",
        "                data[\"invoice_date\"],\n",
        "                data[\"due_date\"],\n",
        "                data[\"customer_name\"],\n",
        "                '\\n'.join(data.get(\"items\", [])),\n",
        "                data[\"taxable_amount\"],\n",
        "                data[\"cgst\"],\n",
        "                data[\"sgst\"],\n",
        "                data[\"total_amount\"],\n",
        "                data[\"total_discount\"],\n",
        "                data[\"total_items_qty\"],\n",
        "                data[\"amount_in_words\"],\n",
        "            ])\n",
        "\n",
        "def print_accuracy(extracted_data_list):\n",
        "    total_invoices = len(extracted_data_list)\n",
        "    column_names = [\n",
        "        \"invoice_number\", \"invoice_date\", \"due_date\", \"customer_name\",\n",
        "        \"taxable_amount\", \"cgst\", \"sgst\", \"total_amount\",\n",
        "        \"total_discount\", \"total_items_qty\", \"amount_in_words\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\nAccuracy of each column:\")\n",
        "    for column in column_names:\n",
        "        filled_count = sum(1 for data in extracted_data_list if data[column] is not None)\n",
        "        accuracy = (filled_count / total_invoices) * 100 if total_invoices > 0 else 0\n",
        "        print(f\"{column.replace('_', ' ').title()}: {filled_count}/{total_invoices}  ({accuracy:.2f}%)\")\n",
        "\n",
        "    # Calculate accuracy for items based on lines vs total quantity\n",
        "    # print(\"\\nItem Count Accuracy:\")\n",
        "    c = 0\n",
        "    error=[]\n",
        "    for data in extracted_data_list:\n",
        "        items = data.get(\"items\", [])\n",
        "        item_count = len(items)  # Number of lines in the items column\n",
        "\n",
        "        # Extract total quantity safely\n",
        "        total_quantity = 0\n",
        "        total_items_qty = data.get(\"total_items_qty\", \"\")\n",
        "        total_quantity=int(total_items_qty)\n",
        "        # print(total_items_qty)\n",
        "\n",
        "\n",
        "\n",
        "        if total_quantity > 0:\n",
        "            if(item_count == total_quantity):\n",
        "                c=c+1\n",
        "            else:\n",
        "                inv = data.get(\"invoice_number\", [])\n",
        "                error.append(inv)\n",
        "\n",
        "    item_accuracy = (c / total_invoices) * 100 if total_invoices > 0 else 0\n",
        "\n",
        "\n",
        "    print(f\"Item Accuracy:{c}/{total_invoices} ({item_accuracy:.2f}%)\")\n",
        "    for inv in error: print(f\"Item Error in file number: {inv}\")\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    extracted_data = process_all_pdfs(pdf_directory)\n",
        "    save_data_to_csv(extracted_data, output_csv)\n",
        "    print_accuracy(extracted_data)\n",
        "\n",
        "print(f\"Data extraction complete. Check {output_csv} for results.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4uCmDKSQ6Ml",
        "outputId": "15e7a779-bb65-4342-a8d6-52731b1737b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing INV-135_Mohith Saragur.pdf...\n",
            "Processing INV-129_Divya Suhane.pdf...\n",
            "Processing INV-118_Rashu.pdf...\n",
            "Processing INV-103_Jaiprakash Kumawat.pdf...\n",
            "Processing INV-99_Indraja.pdf...\n",
            "Processing INV-145_Indraja Mohite.pdf...\n",
            "Processing INV-140_Ankit.pdf...\n",
            "Processing INV-149_Karishma Bande.pdf...\n",
            "Processing INV-112_Gauri.pdf...\n",
            "Processing INV-144_Atia Latif.pdf...\n",
            "Processing INV-133_Sheetal Kapur.pdf...\n",
            "Processing INV-117_Naman.pdf...\n",
            "Processing INV-142_Urmila Jangam.pdf...\n",
            "Processing INV-116_Shefali.pdf...\n",
            "Processing INV-104_Joseph Wincet.pdf...\n",
            "Processing INV-150_Bhusan Naresh.pdf...\n",
            "Processing INV-136_Rishabh Ramola.pdf...\n",
            "Processing INV-106_Kamakshi Thakkar.pdf...\n",
            "Processing INV-138_Agrani Kandele.pdf...\n",
            "Processing INV-113_Raghvendra.pdf...\n",
            "Processing INV-141_Kasturi Kalwar.pdf...\n",
            "Processing INV-147_Divya Suhane.pdf...\n",
            "Processing INV-73_Avik Mallick.pdf...\n",
            "Processing INV-102_Kasturi Kalwar.pdf...\n",
            "Processing INV-124_Ankita Sattva.pdf...\n",
            "Processing INV-107_Prashant.pdf...\n",
            "Processing INV-143_Prashant.pdf...\n",
            "Processing INV-127_Avik Mallick.pdf...\n",
            "Processing INV-121_Jitesh Soni.pdf...\n",
            "Processing INV-115_Akhil Abhay.pdf...\n",
            "Processing INV-110_Kushagra Tiwari.pdf...\n",
            "Processing INV-146_Abhikaran Jalonha.pdf...\n",
            "Processing INV-98_Monika.pdf...\n",
            "Processing INV-100_Agrani Kandele.pdf...\n",
            "Processing INV-134_Sheetal Kapur.pdf...\n",
            "Processing INV-114_Vaibhav Bhagat.pdf...\n",
            "Processing INV-123_Asit.pdf...\n",
            "Processing INV-148_harshit rathore.pdf...\n",
            "Processing INV-128_Atia Latif.pdf...\n",
            "Processing INV-101_Abhikaran Jalonha.pdf...\n",
            "Processing INV-105_Urmila Jangam.pdf...\n",
            "\n",
            "Accuracy of each column:\n",
            "Invoice Number: 41/41  (100.00%)\n",
            "Invoice Date: 41/41  (100.00%)\n",
            "Due Date: 41/41  (100.00%)\n",
            "Customer Name: 41/41  (100.00%)\n",
            "Taxable Amount: 41/41  (100.00%)\n",
            "Cgst: 41/41  (100.00%)\n",
            "Sgst: 41/41  (100.00%)\n",
            "Total Amount: 41/41  (100.00%)\n",
            "Total Discount: 40/41  (97.56%)\n",
            "Total Items Qty: 41/41  (100.00%)\n",
            "Amount In Words: 41/41  (100.00%)\n",
            "Item Accuracy:40/41 (97.56%)\n",
            "Item Error in file number: INV-138\n",
            "Data extraction complete. Check invoice_data_2.csv for results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wM7xP9o8mNjM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}